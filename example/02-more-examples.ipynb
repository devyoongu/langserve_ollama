{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë²ˆì—­ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langserve import RemoteRunnable\n",
    "\n",
    "# ngrok remote ì£¼ì†Œ ì„¤ì •\n",
    "# chain = RemoteRunnable(\"https://poodle-deep-marmot.ngrok-free.app/translate/\")\n",
    "chain = RemoteRunnable(\"https://rat-close-closely.ngrok-free.app/translate/\")\n",
    "\n",
    "# chain = RemoteRunnable(\"NGROK ì—ì„œ ì„¤ì •í•œ ë³¸ì¸ì˜ ë„ë©”ì¸ ì£¼ì†Œ/translate/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì €ëŠ” ë”¥ëŸ¬ë‹ì„ ì‚¬ë‘í•´ìš”"
     ]
    }
   ],
   "source": [
    "for token in chain.stream({\"input\": \"I love deep learning\"}):\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM ì„ Runnableë¡œ ì‹¤í–‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langserve import RemoteRunnable\n",
    "\n",
    "# llm = RemoteRunnable(\"https://poodle-deep-marmot.ngrok-free.app/llm/\")\n",
    "llm = RemoteRunnable(\"https://rat-close-closely.ngrok-free.app/llm/\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"ë‹¤ìŒì˜ ë‚´ìš©ì„ SNS ê²Œì‹œê¸€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ ì£¼ì„¸ìš”:\\n{input}\"\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ğŸ’¡ AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œ ì €ëŠ” ë”¥ëŸ¬ë‹ì— ëŒ€í•œ ì‚¬ë‘ì„ í‘œí˜„í•˜ê³  ì‹¶ì–´í•˜ëŠ” ì—¬ëŸ¬ë¶„ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆì–´ìš”! ì—¬ê¸° ì†Œì…œ ë¯¸ë””ì–´ í”Œë«í¼ì—ì„œ ê³µìœ í•  ìˆ˜ ìˆëŠ” ë§¤ë ¥ì ì¸ ê²Œì‹œê¸€ì´ ìˆìŠµë‹ˆë‹¤:\\n\\n\"ğŸ¤–ğŸ§  #AI ì• í˜¸ê°€ ì—¬ëŸ¬ë¶„, ì£¼ëª©í•˜ì„¸ìš”! ğŸ’¡ğŸŒˆ ì €ëŠ” ë”¥ëŸ¬ë‹ì— ì™„ì „íˆ ë¹ ì ¸ë²„ë ¸ì–´ìš”! ì´ ê°•ë ¥í•œ ê¸°ìˆ ì€ ìš°ë¦¬ê°€ ìƒìƒì¡°ì°¨ ëª»í–ˆë˜ ë°©ì‹ìœ¼ë¡œ ì„¸ìƒì„ ë³€í™”ì‹œí‚¤ê³  ìˆì£ . ğŸ”®ğŸ“Š ìµœì‹  íŠ¸ë Œë“œì™€ í†µì°°ë ¥ì„ ê³µìœ í•˜ë©° í•¨ê»˜ ë°°ìš°ê³  ì„±ì¥í•´ìš”! #DeepLearningRocks\"\\n\\nì´ ê²Œì‹œê¸€ì„ ì—¬ëŸ¬ë¶„ì˜ ì†Œì…œ ë¯¸ë””ì–´ ê³„ì •ì— ê³µìœ í•˜ê³ , ë”¥ëŸ¬ë‹ì— ëŒ€í•œ ì—´ì •ì„ ë‹¤ë¥¸ ì‚¬ëŒë“¤ê³¼ ë‚˜ëˆ„ì„¸ìš”! ğŸš€ğŸ’¡'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"ì €ëŠ” ë”¥ëŸ¬ë‹ì„ ë„ˆë¬´ë‚˜ë„ ì‚¬ë‘í•©ë‹ˆë‹¤.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
